#Now make 2 versions that we'll analyze: simpleOrderStrict, which include only correct glyphs, and
#simpleOrderGenerous which replaces a single X with the missing glyph
toStrict <- function(astring){
astring <- gsub("X", "", astring)
astring <- gsub("Y", "", astring)
astring <- gsub("Z", "", astring)
}
toGenerous <- function(acat, astring){
if (acat %in% c("Inanimate","Animate")){
needed <- c("S","V","O")
} else if (acat %in% c("Intransitive")){
needed <- c("S","V")
}
#remove items until we have just ones that the string doesn't have
isMissing <- c()
for (n in needed){
if (!(str_detect(astring, n))){
isMissing <- append(isMissing, n)
}
}
#If there is exactly 1 missing, replace the X with the missing thing (if it's there)
if(length(isMissing) == 1){
astring <- gsub("X", isMissing[1],astring)
} else if(length(isMissing) > 1){ #couldn't do this one!
astring = "UNFIXABLE"
}
#(otherwise leave it as-is)
return(astring)
}
mydata$simpleOrderStrict <- mapply(toStrict, mydata$simpleOrderRelaxed)
mydata$simpleOrderGenerous <- mapply(toGenerous, mydata$StimCategory, mydata$simpleOrderRelaxed)
#Okay, so at this point we have 3 possible groups we could analyze: people whose strict simple
#order is identical to their raw order, people whose first-mention order is a valid word
#order, and people whose 'generous'/corrected first-mention order is a valid word
passesMuster <- function(acat, astring){ #"please be the correct length! Above filters ensure that there is only 1 copy of each glyph listed in sequences
if (acat %in% c("Inanimate","Animate")){
corrlen = 3
} else if (acat %in% c("Intransitive")){
corrlen = 2
}
#Make sure we don't get trimmed "unfixable" entries
if(astring == "UNFIXABLE"){
astring = ""
}
return(corrlen == nchar(astring))
}
mydata$includeStrict <- mapply(passesMuster, mydata$StimCategory, mydata$simpleOrderStrict)
mydata$includeGenerous <- mapply(passesMuster, mydata$StimCategory, mydata$simpleOrderGenerous)
mydata$includePerfect <- mydata$includeStrict & (mydata$simpleOrderStrict == mydata$RawOrder)
#The isPerfect column allowed us to check what was up with people who had a usable Strict
#condensation (i.e. we got 3/2 'real' glyphs taking the first instance of each) but who did
#not match their ORIGINAL long order.
#There are 64 such instances out of the 4,000ish total responses; some are esoteric word
#orders like SVOV, but many are things like SSOV which indicate they 'dropped' a symbol on the way
###
# Analysis plan!  We have 2 sets of responses: 'readable' responses allowing for people
# to make 1 screwup (allows us to include the most data, which we'll see is a problem),
# and then a stricter one.  We focus on the 'readable' one since it required throwing away
# less data
###
#find & filter out participants who should be excluded because they reported cheating
mydata <- mydata %>%
filter(cheated == 0) %>%
filter(simpleOrderGenerous != 'UNFIXABLE') %>%
filter(StimCategory != "Intransitive") #take just transitives!
#save the main & 'strict' rows, and narrow down to the columns relevant for each of those analyses
vars <- c('participant','trial.number', 'stimnum', 'StimCategory', 'simpleOrderStrict', 'RawOrder')
strictdata <- mydata %>%
filter(includeStrict) %>%
dplyr::select(one_of(vars))
vars <- c('participant','trial.number', 'stimnum', 'StimCategory', 'simpleOrderGenerous','RawOrder')
mydata <- mydata %>%
filter(includeGenerous) %>%
dplyr::select(one_of(vars))
#################################################################
## REPORT DESCRIPTIVES
sum.na.rm <- function(x) { sum(x,na.rm=T) }
my.sd <- function(x) {sd(x)/sqrt(length(x))}
#Report S counts (out of original 292)
subj.count = length(unique(mydata$participant)) #230
#Report counts of Word Order instances
word.order.counts = table(mydata$simpleOrderGenerous, mydata$StimCategory)
#And categorize them!
mydata$Order.Type <- ""
mydata[mydata$simpleOrderGenerous == "SOV",]$Order.Type <- "VerbLateral"
mydata[mydata$simpleOrderGenerous == "OSV",]$Order.Type <- "VerbLateral"
mydata[mydata$simpleOrderGenerous == "VSO",]$Order.Type <- "VerbLateral"
mydata[mydata$simpleOrderGenerous == "VOS",]$Order.Type <- "VerbLateral"
mydata[mydata$simpleOrderGenerous == "SVO",]$Order.Type <- "VerbMedial"
mydata[mydata$simpleOrderGenerous == "OVS",]$Order.Type <- "VerbMedial"
#Report counts of Word Order Type
order.type.counts = table(mydata$Order.Type, mydata$StimCategory)
#Make scores for each participant (we'll use these for graphing confidence intervals...)
mydata$ChoseVLat <- 0
mydata[mydata$Order.Type!="VerbMedial",]$ChoseVLat <- 1
ParticipantScores <- aggregate(mydata$ChoseVLat, by=list(mydata$participant, mydata$StimCategory), mean.na.rm)
names(ParticipantScores) <- c("participant", "ObjectType", "ChoseVLat")
ParticipantScores$ObjectType <- factor(ParticipantScores$ObjectType)
#Table for mean VLat scores, just taking a peak.
with(ParticipantScores, tapply(ChoseVLat, list(ObjectType), mean, na.rm=TRUE), drop=TRUE)
#Repeating the word order counts, let's look at people who produced a non-SVO order at some
#point in the proceedings.
mydata$participant <- as.factor(mydata$participant)
nonSVO <- aggregate(ParticipantScores$ChoseVLat, by=list(ParticipantScores$participant), sum)
names(nonSVO)<- c("participant","nonSVO")
mydata <- merge(mydata, nonSVO)
mixers <- filter(mydata, nonSVO>0)
mixer.order.counts = table(mixers$simpleOrderGenerous, mixers$StimCategory)
word.order.counts = table(mydata$simpleOrderGenerous, mydata$StimCategory)
word.order.counts #from above, all participants
mixer.order.counts
length(unique(mydata$participant))
length(unique(mixers$participant))
mixerParticipantScores <- aggregate(mixers$ChoseVLat, by=list(mixers$participant, mixers$StimCategory), mean.na.rm)
names(mixerParticipantScores) <- c("participant", "ObjectType", "ChoseVLat")
mixerParticipantScores$ObjectType <- factor(mixerParticipantScores$ObjectType)
#Simple histogram of orders
table(mydata$simpleOrderGenerous)
#########
# GRAPHS
#########
ParticipantScores <- mixerParticipantScores
#Bootstrapped confidence intervals
library(bootstrap)
animate.boot.mean = bootstrap(ParticipantScores[ParticipantScores$ObjectType=="Animate",]$ChoseVLat, 1000, mean)
quantile(animate.boot.mean$thetastar, c(0.025, 0.975))
inanimate.boot.mean = bootstrap(ParticipantScores[ParticipantScores$ObjectType=="Inanimate",]$ChoseVLat, 1000, mean)
quantile(inanimate.boot.mean$thetastar, c(0.025, 0.975))
GraphScores <- aggregate(ParticipantScores$ChoseVLat, by=list(ParticipantScores$ObjectType), mean.na.rm)
names(GraphScores) <- c("ObjectType", "ChoseVLat")
GraphScores$errorLow = 0
GraphScores$errorHigh = 0
GraphScores[GraphScores$ObjectType == "Animate",]$errorLow = quantile(animate.boot.mean$thetastar, 0.025)
GraphScores[GraphScores$ObjectType == "Inanimate",]$errorLow = quantile(inanimate.boot.mean$thetastar, 0.025)
GraphScores[GraphScores$ObjectType == "Animate",]$errorHigh = quantile(animate.boot.mean$thetastar, 0.975)
GraphScores[GraphScores$ObjectType == "Inanimate",]$errorHigh = quantile(inanimate.boot.mean$thetastar, 0.975)
GraphScores$ObLabel <- ""
GraphScores[GraphScores$ObjectType == "Inanimate",]$ObLabel <- "Inanimate patient"
GraphScores[GraphScores$ObjectType == "Animate",]$ObLabel <- "Animate patient"
GraphScores <- filter(GraphScores, ObjectType != "Intransitive")
library(RColorBrewer)
my.cols <- brewer.pal(9, "Purples")
my.cols <- c(my.cols[6], my.cols[3])
#Fix for recalcitrant column ordering
GraphScores$ObLabel <- factor(GraphScores$ObLabel, levels = c("Inanimate patient", "Animate patient"))
ggplot(data=GraphScores, aes(x=ObLabel, y=ChoseVLat, fill=ObLabel)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=errorLow, ymax=errorHigh), colour="black", width=.1, position=position_dodge(.9)) +
scale_fill_manual(values=my.cols) +
coord_cartesian(ylim=c(0,1)) +
scale_y_continuous(breaks = seq(0, 1, 0.1))+
xlab('') +
ylab('proportion of SOV-type symbol orders') +
theme_bw() +
theme(legend.title=element_blank())
ggsave('glyphgrid.jpg')
ggsave('glyphgrid.jpg')
R.info()
R.status()
R.version()
help(R)
??R
R.Version
R.Version()
setwd("~/Dropbox/_Projects/Gesture/GlyphGrid_mekline")
## Lines 1-405 were used to clean the big hairy JSON output of the experiment script into a csv
## with raw word orders of cards that participants passed.
##
## MIGUEL SALINAS (masm@mit.edu)
## CODE SKELETON PROVIDED BY MELISSA KLINE (mekline@mit.edu)
## LOAD R-PACKAGES ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
library(stringr)
library(ggplot2)
library(Hmisc)
## CREATE HELPER FUNCTIONS FOR ANALYSIS
mean.na.rm <- function(x) { mean(x,na.rm=T) }
sum.na.rm <- function(x) { sum(x,na.rm=T) }
stderr <- function(x) sqrt(var(x)/length(x))
# READ DATA  ---------------------------------------------------------------
# DATA TAKEN FROM particpants.db WITHIN THE DIRECTORY #
con = dbConnect(SQLite(),dbname = "experiment script/participants.db");
df.complete = dbReadTable(con,"glyphs")
dbDisconnect(con)
# FILTER OUT MTURK HITS THAT WERE NOT FULLY COMPLETED (USING DPLYR METHODS)
df.complete = subset(df.complete, status %in% c(3,4))
#nrow(df.complete) includes all subjects ever plus all debug attempts!
#filter to a particular day (if I haven't set codeversions).
##HERE ARE ALL THE PILOT RUNS -- SOME RUNS WERE DONE IN CHUNKS ON DIFFERENT DAYS##
##PILOTS includes: developing basic script, getting ppl to use clicker, getting them to
##do so quickly, calibrating the timer.
df.complete$currentVersion.pilot1.1 = str_detect(df.complete$beginhit, "2015-03-24")
df.complete$currentVersion.pilot1.2 = str_detect(df.complete$beginhit, "2015-03-25")
df.complete$currentVersion.pilot2 = str_detect(df.complete$beginhit, "2015-05-27")
df.complete$currentVersion.pilot3 = str_detect(df.complete$beginhit, "2015-06-21")
df.complete$currentVersion.pilot4 = str_detect(df.complete$beginhit, "2015-06-24 15:32:10.316064")
df.complete$currentVersion.pilot5.1 = str_detect(df.complete$beginhit, "2015-07-27")
df.complete$currentVersion.pilot5.2 = str_detect(df.complete$beginhit, "2015-07-29")
df.complete$currentVersion.pilot5.3 = str_detect(df.complete$beginhit, "2015-07-30")
df.complete$currentVersion.pilot6 = str_detect(df.complete$beginhit, "2015-09-23 22:33:42.206700")
df.complete$currentVersion.pilot7.1 = str_detect(df.complete$beginhit, "2015-09-23")
df.complete$currentVersion.pilot7.2 = str_detect(df.complete$beginhit, "2015-09-24")
df.complete$currentVersion.pilot8 = str_detect(df.complete$beginhit, "2015-10-07")
##HERE ARE ALL THE LARGER SAMPLES
### RUN#1 - THERE WERE 175 PARTICIPANTS RUN THROUGHOUT 5 DAYS
df.complete$currentVersion.Run1.1 = str_detect(df.complete$beginhit, "2015-07-31")
df.complete$currentVersion.Run1.2 = str_detect(df.complete$beginhit, "2015-08-01")
df.complete$currentVersion.Run1.3 = str_detect(df.complete$beginhit, "2015-08-02")
df.complete$currentVersion.Run1.4 = str_detect(df.complete$beginhit, "2015-08-11")
df.complete$currentVersion.Run1.5 = str_detect(df.complete$beginhit, "2015-08-12")
### RUN#2 - THERE WERE 130 PARTICIPANTS RUN THROUGHOUT 5 DAYS
df.complete$currentVersion.Run2.1 = str_detect(df.complete$beginhit, "2015-10-08")
df.complete$currentVersion.Run2.2 = str_detect(df.complete$beginhit, "2015-10-09")
df.complete$currentVersion.Run2.3 = str_detect(df.complete$beginhit, "2015-10-10")
df.complete$currentVersion.Run2.4 = str_detect(df.complete$beginhit, "2015-10-13")
df.complete$currentVersion.Run2.5 = str_detect(df.complete$beginhit, "2015-10-14")
df.complete$currentVersion.Run2.6 = str_detect(df.complete$beginhit, "2015-10-15")
#PILOT 1, 03/24/2015 - 03/25/2015
#df.complete = df.complete[df.complete$currentVersion.pilot1.1 == TRUE | df.complete$currentVersion.pilot1.2 == TRUE,]
#PILOT 2, 05/27/2015
#df.complete = df.complete[df.complete$currentVersion.pilot2 == TRUE,]
#PILOT 3, 06/21/2015
#df.complete = df.complete[df.complete$currentVersion.pilot3 == TRUE,]
#To get Trial Times 06/24/2015 CLICK -- ONLY ONE PARTICIPANT RUN FOR GETTING TRIAL TIME ESTIMATES (MELANIE)
#df.complete = df.complete[df.complete$currentVersion.pilot4 == TRUE,]
#PILOT 4, 07/27/2015 - TRIALS RUN WITH WORKING TIMER. ALSO, THE DRAG OPTION WAS REPLACED BY THE CLICK OPTION.
#df.complete = df.complete[df.complete$currentVersion.pilot5.1 == TRUE|df.complete$currentVersion.pilot5.2 == TRUE|df.complete$currentVersion.pilot5.3 == TRUE,]
#To get Trial Times 09/23/2015 CLICK -- ONLY ONE PARTICIPANT RUN FOR GETTING TRIAL TIME ESTIMATES (LAURA)
#df.complete = df.complete[df.complete$currentVersion.pilot6 == TRUE,]
#PILOT 7, 09/23/2015 - TRIALS RUN WITH WORKING TIMER. ALSO, THE DRAG OPTION WAS REPLACED BY THE CLICK OPTION.
#df.complete = df.complete[df.complete$currentVersion.pilot7.1 == TRUE|df.complete$currentVersion.pilot7.2 == TRUE,]
#PILOT 8, 10/07/2015 - PARTICIPANTS MUST TAKE THE QUIZ TWO TIMES
#df.complete = df.complete[df.complete$currentVersion.pilot8 == TRUE,]
#FIRST LARGE SAMPLE! WILL INCLUDE PARTICIPANTS RUN FROM 1.1 TO 1.5
#df.complete = df.complete[df.complete$currentVersion.Run1.1 == TRUE|df.complete$currentVersion.Run1.2 == TRUE|df.complete$currentVersion.Run1.3 == TRUE|df.complete$currentVersion.Run1.4 == TRUE|df.complete$currentVersion.Run1.5 == TRUE,]
#SECOND LARGE SAMPLE! WILL INCLUDE PARTICIPANTS RUN FROM 2.1 TO 2.6
#df.complete = df.complete[df.complete$currentVersion.Run2.1 == TRUE|df.complete$currentVersion.Run2.2 == TRUE|df.complete$currentVersion.Run2.3 == TRUE|df.complete$currentVersion.Run2.4 == TRUE|df.complete$currentVersion.Run2.5 == TRUE|df.complete$currentVersion.Run2.6 == TRUE,]
#BOTH LARGE SAMPLES, 1.1-2.6
df.complete = df.complete[df.complete$currentVersion.Run1.1 == TRUE|df.complete$currentVersion.Run1.2 == TRUE|df.complete$currentVersion.Run1.3 == TRUE|df.complete$currentVersion.Run1.4 == TRUE|df.complete$currentVersion.Run1.5 == TRUE|df.complete$currentVersion.Run2.1 == TRUE|df.complete$currentVersion.Run2.2 == TRUE|df.complete$currentVersion.Run2.3 == TRUE|df.complete$currentVersion.Run2.4 == TRUE|df.complete$currentVersion.Run2.5 == TRUE|df.complete$currentVersion.Run2.6 == TRUE,]
nrow(df.complete)
#FILTER OUT any remaining 'debug' PARTICIPANTS!
df.complete = filter(df.complete, !str_detect(df.complete$workerid,"debug"))
nrow(df.complete)
# STRUCTURE DATA ----------------------------------------------------------
#NOTE: COMPILE IN WIDE FORM: 1 ROW/PARTICIPANT; EACH TRIAL GETS A SERIES OF COLUMN NAMES, FORMATTED XYFIELD_#
#ALSO, NO EXTRA UNDERSCORES IN THE COLUMN NAMES, THIS BREAKS wideToLong
df.wide = data.frame(NULL)
df.wide = data.frame(matrix(nrow=nrow(df.complete),ncol=4))
colnames(df.wide) = c("participant","workerId","browser","beginhit") #DYNAMICALLY ADDS COLUMNS FROM THE DATASTRING BELOW
#ORGANIZE DATA -------------------------------------------------------------
#GLOBAL INDECES ARE NUMBERS CORRESPONDING TO THE PAGE NUMBER THAT THE PARTICIPANT SAW
global_indeces = c()
#free_sorts WILL INCLUDE TRIALS OF TYPE 'free-sort' ONLY - THERE SHOULD BE 22 PER PARTICIPANT
#18 OF THESE ARE ACTUAL TEST TRIALS
free_sorts = list()
#categorized WILL INCLUDE TRIALS OF TYPE 'categorized' WHICH ARE USED TO QUIZ THE PARTICIPANT'S MEMORIZATION OF THE GLYPHS
#THESE TRIALS ARE RUN IN GROUPS OF 16. PARTICIPANT CAN TAKE THE QUIZ AS MANY TIMES AS NEEDED
categorized = list()
for (i in 1:nrow(df.wide)){
partic_free = list()
partic_catg = list()
if (!is.na(df.complete$datastring[i])){
a = fromJSON(df.complete$datastring[i])
mylength = length(a$data)
} else{
a = data.frame(NULL)
mylength = 0
}
print(mylength)
if (mylength>=51){
df.wide$participant[i] = i
df.wide$workerId[i] = a$workerId
df.wide$browser[i] = df.complete$browser[i]
df.wide$beginhit[i] = df.complete$beginhit[i]
#cycle through all the trials, but only record where isTestTrial = 1
for (j in 1:mylength){
if(a$data[[j]]$trialdata$trial_type == "free-sort"){
partic_free = c(partic_free, list(a$data[[j]]$trialdata))
} else if (a$data[[j]]$trialdata$trial_type == "categorize") {
partic_catg = c(partic_catg, list(a$data[[j]]$trialdata))
}
}
free_sorts[a$workerId] = list(partic_free)
categorized[a$workerId] = list(partic_catg)
} else {
df.wide[i,] = 'EXCLUDED'
df.wide$workerId[i] = a$workerId
}
#And grab the info we need from the last 'trial' (feedback)
if (is.null(a$data[[mylength-1]]$trialdata$responses)){df.wide$feedback[i] = "none"
} else {
df.wide$feedback[i] = a$data[[mylength-1]]$trialdata$responses
}
}
#Check we didn't lose anyone there
nrow(df.wide)
#### CHECK TO SEE IF PARTICIPANT CHEATED (IE did they say they cheated when we asked) ####
df.wide$cheated = as.numeric(grepl('Q1\":\"y', df.wide$feedback, ignore.case=TRUE) | grepl('Q2\":\"y', df.wide$feedback, ignore.case=TRUE))
##INSERT QUIZ DATA TO WIDE DATA FRAME##
df.wide$NumQuizTries = 'NoInputYet'
df.wide$LastQuizScore = 'NoInputYet'
for (i in 1:length(names(categorized))) {
myquizlength = length(categorized[[names(categorized)[i]]])
df.wide$NumQuizTries[which(df.wide$workerId %in% names(categorized)[i])] = as.double(myquizlength/16)
tot_score = numeric()
for (j in (myquizlength-15):myquizlength) {
tot_score = c(tot_score, categorized[[names(categorized)[i]]][[j]]$correct)
}
df.wide$LastQuizScore[which(df.wide$workerId %in% names(categorized)[i])] = as.double(mean(tot_score))
}
median(as.numeric(as.character(df.wide$NumQuizTries)))
##LABEL PARTICIPANTS THAT HAD TOO MANY OR TOO FEW TRIALS, AND EXCLUDE##
##OTHERWISE GRAB EACH TRIALS DATA##
worker_ids = names(free_sorts)
for (i in 1:length(worker_ids)) {
if (length(free_sorts[[worker_ids[i]]]) != 22) {
grabbed_row = which(df.wide$workerId %in% worker_ids[i])
df.wide[grabbed_row,] = 'EXCLUDED'
df.wide$participant[grabbed_row] = as.numeric(grabbed_row)
df.wide$workerId[grabbed_row] = worker_ids[i]
df.wide$beginhit[grabbed_row] = 'TOO MANY TRIALS'
}
}
for (i in 1:nrow(df.wide)){
counter = 1
if (!str_detect(df.wide$browser[i], 'EXCLUDED')){
a = free_sorts[[df.wide$workerId[i]]]
mylength = length(free_sorts[[df.wide$workerId[i]]])
for (j in mylength:1) {
if(j == mylength) {max_g_i = free_sorts[[df.wide$workerId[i]]][[j]]$trial_index_global}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$glyph)){
trial_num = (28 - (max_g_i - free_sorts[[df.wide$workerId[i]]][[j]]$trial_index_global))
df.wide[[paste("glyph_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$glyph
df.wide[[paste("Stimulus_",trial_num, sep="")]][i] = "PracticeImage"
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$moviefile)){
trial_num = (26 - (max_g_i - free_sorts[[df.wide$workerId[i]]][[j]]$trial_index_global))
df.wide[[paste("Stimulus_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$moviefile
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$isTestTrial)){
if(free_sorts[[df.wide$workerId[i]]][[j]]$isTestTrial == 1) {
df.wide[[paste("isTestTrial_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$isTestTrial
}}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$moves)){
df.wide[[paste("moves_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$moves
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$Sub)){
df.wide[[paste("S_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$Sub
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$Vrb)){
df.wide[[paste("V_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$Vrb
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$Obj)){
df.wide[[paste("O_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$Obj
}
if(!is.null(free_sorts[[df.wide$workerId[i]]][[j]]$rt)){
df.wide[[paste("rt_",trial_num, sep="")]][i] = free_sorts[[df.wide$workerId[i]]][[j]]$rt
}
}
} else{
a = data.frame(NULL)
mylength = 0
grabbed_row = which(df.wide$workerId %in% worker_ids[i])
df.wide[grabbed_row,] = 'EXCLUDED'
df.wide$participant[grabbed_row] = as.numeric(grabbed_row)
df.wide$workerId[grabbed_row] = worker_ids[i]
df.wide$beginhit[grabbed_row] = 'TOO MANY TRIALS'
}
} #End of this participant
##PREP FOR GETTING RAW WORD ORDER##
names = c('moves_', "S_", "O_", "V_", "glyph_")
col.names = names(df.wide)
col.nums = c()
where_moves = which(str_detect(col.names, 'moves'))
for (w in 1:length(where_moves)) {
col.nums = unique(c(col.nums, unlist(strsplit(col.names[where_moves][w], split='moves_'))))
}
col.nums = as.numeric(col.nums[-which(col.nums %in% "")])
col.nums = sort(col.nums)
df.wide[paste('RawOrd_', col.nums, sep='')] = 'NoOrderYet'
for (i in 1:length(col.nums)){
if (!exists(paste("isTestTrial_",col.nums[i], sep=""), where=df.wide)){
df.wide[paste("isTestTrial_",col.nums[i], sep="")] = 0
}
}
###GET RAW WORD ORDER###
for (j in 1:nrow(df.wide)){
if (df.wide$browser[j] != "EXCLUDED"){
for (k in 1:length(col.nums)) {
if (df.wide[paste('Stimulus_', col.nums[k], sep = "")][j,] == "PracticeImage") {
check_m = df.wide[paste(names[1], col.nums[k], sep = "")][j,]
check_m = unlist(strsplit(check_m, split='{\"src\":\"', fixed=TRUE))
check_m = unlist(strsplit(check_m, split='.png\",', fixed=TRUE))
check_m = check_m[which(str_detect(check_m, 'g'))]
check_g = df.wide[paste(names[5], col.nums[k], sep = "")][j,]
where_g = ''
check_m[which(unlist(gregexpr(check_g, check_m)) == 1)] = 'G'
choices = c('X', 'Y', 'Z', 'Q', 'H', 'W', 'R')
choice_num = 0
while (mean(str_detect(check_m, 'g')) > 0) {
choice_num = choice_num + 1
which_g = check_m[which(grepl('g', check_m))][1]
check_m[which(str_detect(check_m, which_g))] = choices[choice_num]
}
if (length(check_m) > 0) {
word_order = paste0(check_m, collapse='')
} else {word_order = 'NONE'}
} else if (df.wide[paste('Stimulus_', col.nums[k], sep = "")][j,] != "") {
check_m = df.wide[paste(names[1], col.nums[k], sep = "")][j,]
check_m = unlist(strsplit(check_m, split='{\"src\":\"', fixed=TRUE))
check_m = unlist(strsplit(check_m, split='.png\",', fixed=TRUE))
check_m = check_m[which(str_detect(check_m, 'g'))]
check_s = df.wide[paste(names[2], col.nums[k], sep = "")][j,]
check_o = df.wide[paste(names[3], col.nums[k], sep = "")][j,]
check_v = df.wide[paste(names[4], col.nums[k], sep = "")][j,]
where_s = where_o = where_v = ''
check_m[which(unlist(gregexpr(check_s, check_m)) == 1)] = 'S'
check_m[which(unlist(gregexpr(check_o, check_m)) == 1)] = 'O'
check_m[which(unlist(gregexpr(check_v, check_m)) == 1)] = 'V'
choices = c('X', 'Y', 'Z', 'Q', 'H', 'W', 'R')
choice_num = 0
if (length(check_m) != 0) {
while (mean(str_detect(check_m, 'g')) > 0) {
choice_num = choice_num + 1
which_g = check_m[which(grepl('g', check_m))][1]
check_m[which(str_detect(check_m, which_g))] = choices[choice_num]
}}
if (length(check_m) > 0) {
word_order = paste0(check_m, collapse='')
} else {word_order = 'NONE'}
} else {word_order = 'NONE'}
df.wide[paste('RawOrd_', col.nums[k], sep = "")][j,] = word_order
}
}
}
###CLEAN UP EXCLUSION ROWS
for (i in 1:nrow(df.wide)) {
if (df.wide$browser[i] == 'EXCLUDED') {
grabbed_row = i
df.wide[grabbed_row,] = 'EXCLUDED'
df.wide$participant[grabbed_row] = as.numeric(grabbed_row)
df.wide$workerId[grabbed_row] = worker_ids[i]
df.wide$beginhit[grabbed_row] = 'TOO MANY TRIALS'
}
}
##GROUP INDIVIDUAL GLYPH COLUMNS INTO ONE COLUMN##
nec.glyphs = function(S, O, V) {
final_group = ''
final_group = paste("S:", S, sep='')
final_group = paste(final_group, ' O:', sep='')
final_group = paste(final_group, O, sep='')
final_group = paste(final_group, ' V:', sep='')
final_group = paste(final_group, V, sep='')
}
glyphs.group = ''
for (i in 1:length(col.nums)) {
if (df.wide[paste('Stimulus_', col.nums[i], sep = "")][1,] != "PracticeImage") {
df.wide[paste("Glyphs_",col.nums[i], sep="")] = mapply(nec.glyphs, S=df.wide[[paste("S_",col.nums[i], sep="")]], O=df.wide[[paste("O_",col.nums[i], sep="")]], V=df.wide[[paste("V_",col.nums[i], sep="")]])
} else {df.wide[paste("Glyphs_",col.nums[i], sep="")] = df.wide[paste("glyph_",col.nums[i], sep="")]}
}
#df.wide <- data.frame(matrix(unlist(df.wide), nrow=nrow(df.wide), byrow=T))
#Make sure nobody got lost! should be 292 still
nrow(df.wide)
###REFORMAT FROM WIDE TO LONG###
moves_list = c()
stimulus_list = c()
rt_list = c()
S_list = c()
O_list = c()
V_list = c()
order_list = c()
glyphs_list = c()
rem.glyph = c()
isTestTrial_list = c()
for (i in 1:length(col.nums)) {
if (exists(paste('S_', col.nums[i], sep=''), df.wide)) {
moves_list = c(moves_list, paste("moves_",col.nums[i], sep=""))
stimulus_list = c(stimulus_list, paste("Stimulus_",col.nums[i], sep=""))
rt_list = c(rt_list, paste("rt_",col.nums[i], sep=""))
S_list = c(S_list, paste("S_",col.nums[i], sep=""))
O_list = c(O_list, paste("O_",col.nums[i], sep=""))
V_list = c(V_list, paste("V_",col.nums[i], sep=""))
order_list = c(order_list, paste("RawOrd_",col.nums[i], sep=""))
glyphs_list = c(glyphs_list, paste("Glyphs_",col.nums[i], sep=""))
isTestTrial_list = c(isTestTrial_list, paste("isTestTrial_",col.nums[i], sep=""))
} else {
moves_list = c(moves_list, paste("moves_",col.nums[i], sep=""))
stimulus_list = c(stimulus_list, paste("Stimulus_",col.nums[i], sep=""))
rt_list = c(rt_list, paste("rt_",col.nums[i], sep=""))
order_list = c(order_list, paste("RawOrd_",col.nums[i], sep=""))
glyphs_list = c(glyphs_list, paste("Glyphs_",col.nums[i], sep=""))
rem.glyph = c(rem.glyph, paste("glyph_",col.nums[i], sep=""))
isTestTrial_list = c(isTestTrial_list, paste("isTestTrial_",col.nums[i], sep=""))
}
}
list_of_lists = list(stimulus_list, rt_list, glyphs_list, moves_list, isTestTrial_list, order_list) #literal_list, keypress_list, match_list)
df.long <- reshape(df.wide,
varying = list_of_lists,
v.names = c('stimulus', 't.time', 'glyphs', 'moves', 'isTestTrial', 'RawOrder'),
timevar = "trial.number",
times = 1:length(moves_list),
drop = c(S_list, O_list, V_list, rem.glyph),
direction = "long")
#Check!
length(unique(df.long$participant))
write.csv(df.long, file="alldata.csv", row.names = FALSE)
library(packrat)
packrat::init()
